{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root = \"./data/\",\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "testset = datasets.FashionMNIST(\n",
    "    root = \"./data/\",\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "train_loader = data.DataLoader(  # 에폭마다 네트워크에 데이터를 주입해줌\n",
    "    dataset = trainset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = data.DataLoader(\n",
    "    dataset = testset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net().to(DEVICE)  # cpu 혹은 cuda로 네트워크를 보냄\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train()  # 모델을 학습 모드로 전환, 드롭아웃 등의 레이어에서 동작이 다름\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)  # 데이터도 처리할 디바이스로 보내야 함\n",
    "        optimizer.zero_grad()  # 매 반복마다 기울기를 새로 계산해야 함\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)  # 결과물과 정답 사이 크로스엔트로피 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 수정\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()  # 모델을 평가 모드로 전환\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():  # 평가시엔 기울기 계산 필요없음\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            test_loss += F.cross_entropy(output, target, reduction=\"sum\").item()\n",
    "\n",
    "            pred = output.max(1, keepdim=True)[1]  # 모델의 예측 클래스\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  # 정답이면 +1\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 0.8551, Accuracy: 67.41%\n",
      "[2] Test Loss: 0.6732, Accuracy: 75.62%\n",
      "[3] Test Loss: 0.5994, Accuracy: 78.62%\n",
      "[4] Test Loss: 0.5492, Accuracy: 80.55%\n",
      "[5] Test Loss: 0.5153, Accuracy: 81.66%\n",
      "[6] Test Loss: 0.5035, Accuracy: 82.26%\n",
      "[7] Test Loss: 0.4830, Accuracy: 83.11%\n",
      "[8] Test Loss: 0.4666, Accuracy: 83.57%\n",
      "[9] Test Loss: 0.4741, Accuracy: 83.18%\n",
      "[10] Test Loss: 0.4554, Accuracy: 83.91%\n",
      "[11] Test Loss: 0.4555, Accuracy: 83.84%\n",
      "[12] Test Loss: 0.4428, Accuracy: 84.27%\n",
      "[13] Test Loss: 0.4338, Accuracy: 84.68%\n",
      "[14] Test Loss: 0.4344, Accuracy: 84.58%\n",
      "[15] Test Loss: 0.4205, Accuracy: 85.08%\n",
      "[16] Test Loss: 0.4221, Accuracy: 85.13%\n",
      "[17] Test Loss: 0.4226, Accuracy: 84.95%\n",
      "[18] Test Loss: 0.4081, Accuracy: 85.62%\n",
      "[19] Test Loss: 0.4150, Accuracy: 85.17%\n",
      "[20] Test Loss: 0.4118, Accuracy: 85.25%\n",
      "[21] Test Loss: 0.4072, Accuracy: 85.50%\n",
      "[22] Test Loss: 0.3984, Accuracy: 85.50%\n",
      "[23] Test Loss: 0.3901, Accuracy: 86.07%\n",
      "[24] Test Loss: 0.3987, Accuracy: 85.83%\n",
      "[25] Test Loss: 0.3883, Accuracy: 86.06%\n",
      "[26] Test Loss: 0.3940, Accuracy: 85.55%\n",
      "[27] Test Loss: 0.3849, Accuracy: 86.30%\n",
      "[28] Test Loss: 0.3821, Accuracy: 86.38%\n",
      "[29] Test Loss: 0.3816, Accuracy: 86.68%\n",
      "[30] Test Loss: 0.3978, Accuracy: 85.68%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "\n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
